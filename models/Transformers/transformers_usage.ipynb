{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
      "tensor([[33331,   502,   257, 25607,  1621]])\n",
      "<class 'torch.Tensor'>\n",
      "final_outputs = tensor([[33331,   502,   257, 25607,  1621,   546,   703,   314,  1392,   656,\n",
      "           262,   983,   290,   644,   314,  4499,   422,   340,    13,   314,\n",
      "           892,   340,   338,  2495,  3608,    11,   290,   314,  1101,  1654,\n",
      "           340,   338,   257,   922,  1621,    13,   198,   198,    40,   892,\n",
      "           340,   338,   257,  2495,  3608,   983,   290,   314,  1101,  1654,\n",
      "           340,   338,   257,   922,  1621,    13,   314,   892,   262,  1621,\n",
      "           318,  2495,   922,    13,   198,   198,    40,   892,   262,  1621,\n",
      "           318,  2495,   922,    13,   198,   198,    40,   892,   262,  1621,\n",
      "           318,  2495,   922,    13,   198,   198,    40,   892,   262,  1621,\n",
      "           318,  2495,   922,    13,   198,   198,    40,   892,   262,  1621]]), type(final_outputs) = <class 'torch.Tensor'>, final_outputs.shape = torch.Size([1, 100])\n",
      "tell me a fairy story about how I got into the game and what I learned from it. I think it's pretty cool, and I'm sure it's a good story.\n",
      "\n",
      "I think it's a pretty cool game and I'm sure it's a good story. I think the story is pretty good.\n",
      "\n",
      "I think the story is pretty good.\n",
      "\n",
      "I think the story is pretty good.\n",
      "\n",
      "I think the story is pretty good.\n",
      "\n",
      "I think the story\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"/home/lihao/model/gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"/home/lihao/model/gpt2\")\n",
    "print(type(model))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lihao/conda/miniconda3/envs/torch-dev/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
      "tensor([[33331,   502,   257, 25607,  1621]])\n",
      "<class 'torch.Tensor'>\n",
      "final_outputs = tensor([[33331,   502,   257, 25607,  1621,    11,   314,  1101,   407,  1016,\n",
      "           284,  1560,   345,   257, 25607,  1621,    11,   475,   314,  1101,\n",
      "          1016,   284,  1560,   345,   257,  1621,   326,   318,   845,    11,\n",
      "           845,  1180,   422,   262, 25607, 12838,   326,   314,  1053,   587,\n",
      "          1297,   526,   198,   198,   464,  1621,   318,  1912,   319,   257,\n",
      "          1103,  1621,   326,   373,  1297,   416,   257,   582,  3706,  3977,\n",
      "            13,   198,   198,     1,  1544,   373,   262,   582,   508,  1297,\n",
      "           502,   262, 12838,   553,   339,  1139,    13,   366,    40,   373,\n",
      "           262,   691,   530,   508,   714,  1560,   340,   526,   198,   198,\n",
      "           464,  1621,  6140,   287,   257, 10016,  3240,   287,   262,  1578]]), type(final_outputs) = <class 'torch.Tensor'>, final_outputs.shape = torch.Size([1, 100])\n",
      "tell me a fairy story, I'm not going to tell you a fairy story, but I'm going to tell you a story that is very, very different from the fairy tale that I've been told.\"\n",
      "\n",
      "The story is based on a real story that was told by a man named William.\n",
      "\n",
      "\"He was the man who told me the tale,\" he says. \"I was the only one who could tell it.\"\n",
      "\n",
      "The story begins in a rural town in the United\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"/home/lihao/model/gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"/home/lihao/model/gpt2\")\n",
    "print(type(model))\n",
    "\n",
    "# 单请求\n",
    "q = \"tell me a fairy story\"\n",
    "\n",
    "ids = tokenizer.encode(q, return_tensors='pt')\n",
    "print(ids)\n",
    "print(type(ids))\n",
    "final_outputs = model.generate(\n",
    "    ids,\n",
    "    do_sample=True,\n",
    "    max_length=100,\n",
    "    pad_token_id=model.config.eos_token_id,\n",
    "    top_k=3,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "print(\"final_outputs = {}, type(final_outputs) = {}, final_outputs.shape = {}\".format(final_outputs, type(final_outputs), final_outputs.shape))\n",
    "\n",
    "print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lihao/conda/miniconda3/envs/torch-dev/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(output1) = <class 'list'>, len(output1) = 9\n",
      "answers: Once upon a time in a magical forestThe U.S. Supreme Court is set to hear arguments on whether the government can force a state to provide health care to its citizens without a warrant, a move that has been hailed by some as a step toward a more open and transparent system of health care.\n",
      "\n",
      "The justices will hear arguments on Wednesday in the case, which is expected to be heard in Washington state on June 6.\n",
      "\n",
      "The case, U.S\n",
      "answers: Once upon a time in a magical forestThe U.S. Supreme Court on Thursday ruled that a Texas school district can ban a teacher from teaching a class about homosexuality, saying it's not in the public interest to ban it.\n",
      "\n",
      "A district court in Houston ruled on Friday that a Texas law that requires teachers to teach about homosexuality is unconstitutional.\n",
      "\n",
      "The case is the latest step in a long-running fight over the school district's ban of gay-straight alliance\n",
      "answers: Once upon a time in a magical forestThis is the first of three posts in a series about the new and improved version of the Windows 10 Mobile operating system, the Windows Phone 8.1 operating system. This is the first post of the series about the Windows Phone 8.1 operating system, the Windows Phone 8.1 operating system. This is the first post of the series about the Windows Phone 8.1 operating system, the Windows Phone 8.1 operating system.\n",
      "answers: In a distant galaxy, a young hero embarks on a quest to rescue his family and his beloved daughter from the dark side of the Force.\n",
      "\n",
      "The Force is strong with a dark side. And when the Force is strong, the Force will be strong with a dark side.\n",
      "answers: In a distant galaxy, a young hero embarks on a quest to save his family from the clutches of a ruthless criminal.\n",
      "\n",
      "Ages 5-12\n",
      "\n",
      "In a distant galaxy, a young hero embarks on a quest to save his family from the clutches of a ruthless criminal.\n",
      "\n",
      "BEST SPOILER ALERT\n",
      "\n",
      "This story contains spoilers for the next chapter.\n",
      "\n",
      "The story begins on the planet Earth.\n",
      "\n",
      "In a distant galaxy, a young\n",
      "answers: In a distant galaxy, a young hero embarks on a quest to find a way to stop the Dark Lord. He is joined by the rest of the heroes of the galaxy, who are joined by a group of heroes who are trying to stop the Dark Lord's plans.\n",
      "\n",
      "Contents show]\n",
      "\n",
      "Summary Edit\n",
      "\n",
      "In the distant galaxy of the Milky Way Galaxy, a young hero embarks on a quest to find a way to stop the Dark Lord. He is joined by the rest\n",
      "answers: A curious cat discovers a hidden treasureThe UESPWiki – Your source for The Elder Scrolls since 1995\n",
      "\n",
      "The following is a list of all the known and unknown items in Skyrim. The list is not complete, and may be incomplete.\n",
      "\n",
      "Note: This list is based on a general consensus, but is based on the most current information. The following items are known only to the author, and may not have been confirmed by the game developers.\n",
      "\n",
      "\n",
      "answers: A curious cat discovers a hidden treasureThe first of the two major U.S. Senate races is over in Michigan.\n",
      "\n",
      "The Republican-controlled state Senate is set to hold a special election Tuesday in which the state Senate will decide on whether to hold the first of two statewide races for governor in 2016.\n",
      "\n",
      "The first of the two major U.S. Senate races is over in Michigan, which is one of the most competitive in the country.\n",
      "\n",
      "\n",
      "answers: A curious cat discovers a hidden treasureThe first thing I thought when I saw that the first episode of The Walking Dead season three finale was coming out, I knew it had to be a good one. The first season of the show was a great one, but I had to give up on it because it was too long. I was so excited to watch this show.\n",
      "\n",
      "I'm not saying that I'm a fan of the show, but I was a little\n"
     ]
    }
   ],
   "source": [
    "# 带 batch 的请求\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"/home/lihao/model/gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"/home/lihao/model/gpt2\")\n",
    "print(type(model))\n",
    "\n",
    "# https://blog.csdn.net/shui123546yi/article/details/134823641\n",
    "\n",
    "# 输入提示（批量）\n",
    "prompts = [\n",
    "    \"Once upon a time in a magical forest\",\n",
    "    \"In a distant galaxy, a young hero embarks on a quest\",\n",
    "    \"A curious cat discovers a hidden treasure\"\n",
    "]\n",
    "\n",
    "# ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 编码输入文本（批量）\n",
    "# 注意，tokenizer.encode 会有问题，建议用 tokenizer 直接搞。返回的 ids 实际上是个 torch 的 tensor\n",
    "ids = tokenizer(prompts, return_tensors='pt', padding=True, truncation=True, max_length=512)[\"input_ids\"]\n",
    "\n",
    "\n",
    "final_outputs = model.generate(\n",
    "    ids,\n",
    "    do_sample=True,\n",
    "    max_length=100,\n",
    "    pad_token_id=model.config.eos_token_id,\n",
    "    top_k=3,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=3 # 每个输入（batch 中的某一条），返回几条数据，默认 1，\n",
    ")\n",
    "\n",
    "#print(\"final_outputs = {}, type(final_outputs) = {}, final_outputs.shape = {}\".format(final_outputs, type(final_outputs), final_outputs.shape))\n",
    "# tokenizer.batch_decode 比 tokenizer.decode(final_outputs[0], skip_special_tokens=True) 屌\n",
    "output1 = tokenizer.batch_decode(final_outputs, skip_special_tokens=True)\n",
    "# print(\"output1 = {}, type(output1) = {}, len(output1) = {}\".format(output1, type(output1), len(output1)))\n",
    "print(\"type(output1) = {}, len(output1) = {}\".format(type(output1), len(output1)))\n",
    "\n",
    "for result in output1:\n",
    "    print(\"answers: {}\".format(result))\n",
    "\n",
    "# print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))\n",
    "# i = 0\n",
    "# for idx in final_outputs:\n",
    "#     print(\"{} {}\".format(i, idx))\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Tokenizer(name_or_path='/home/lihao/model/gpt2', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "}\n",
      "<class 'transformers.models.gpt2.tokenization_gpt2.GPT2Tokenizer'>\n",
      "[15496, 995]\n",
      "[18435, 995]\n",
      "tensor([[ 7454,  2402,   257,   640,   287,   257, 10883,  8222, 50256, 50256,\n",
      "         50256, 50256, 50256],\n",
      "        [  818,   257, 12899, 16161,    11,   257,  1862,  4293,  4072,  5558,\n",
      "           319,   257,  1235],\n",
      "        [   32, 11040,  3797, 27472,   257,  7104, 14068, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256]])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"/home/lihao/model/gpt2\")\n",
    "\n",
    "print(tokenizer)\n",
    "print(type(tokenizer))\n",
    "\n",
    "prompts = [\n",
    "    \"Once upon a time in a magical forest\",\n",
    "    \"In a distant galaxy, a young hero embarks on a quest\",\n",
    "    \"A curious cat discovers a hidden treasure\"\n",
    "]\n",
    "\n",
    "print(tokenizer(\"Hello world\")[\"input_ids\"])\n",
    "print(tokenizer(\" Hello world\")[\"input_ids\"])\n",
    "# padding=True,\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data = tokenizer(prompts, return_tensors=\"pt\", truncation=True, padding=True)[\"input_ids\"]\n",
    "print(data)\n",
    "print(type(data))\n",
    "print(type(data[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
